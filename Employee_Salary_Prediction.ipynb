{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Employee Salary Prediction using Random Forest Technique**"
      ],
      "metadata": {
        "id": "2IVRq3SgFLEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 01: Loading and Inspecting the Dataset"
      ],
      "metadata": {
        "id": "Acu6BBCOFm_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset from the provided URL\n",
        "#The dataset used for this project is hosted by UCI Machine Learning Repository\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "columns = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "    'hours-per-week', 'native-country', 'salary'\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, header=None, names=columns, na_values=' ?', sep=',\\s*', engine='python')\n",
        "\n",
        "#Prints the first 5 rows of the dataset\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "UEuked18BY9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prints the Summary of the Dataset\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "djwbxTMFB02Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Data Cleaning and Handling Missing Values"
      ],
      "metadata": {
        "id": "ndgMYHtCFypi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in each column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "P1YQFIkbC1Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We will be filling missing values using the mode\n",
        "for col in ['workclass', 'occupation', 'native-country']:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "6wgTWPVxC9lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that there are no more missing values\n",
        "print(\"\\nMissing values after cleaning:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "ERZksSffDOY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "6g_MDgQaF73K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Set the style for plots\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "metadata": {
        "id": "dUVazRiuDeLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Salary Distribution (Target Variable)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x='salary')\n",
        "plt.title('Distribution of Salary Classes')\n",
        "plt.xlabel('Salary')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QMqr1noeDrXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Age Distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['age'], bins=30, kde=True)\n",
        "plt.title('Distribution of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u3Yw7khvD4gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Salary vs. Hours per Week\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df, x='salary', y='hours-per-week')\n",
        "plt.title('Salary vs. Hours per Week')\n",
        "plt.xlabel('Salary')\n",
        "plt.ylabel('Hours per Week')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1HG05BL6EXRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the target variable 'salary' to binary (0 and 1)\n",
        "df['salary'] = df['salary'].apply(lambda x: 1 if x == '>50K' else 0)"
      ],
      "metadata": {
        "id": "-2NXhX1cEmoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Preprocessing the data"
      ],
      "metadata": {
        "id": "0Xd_YWq-GKiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encode categorical features\n",
        "# This creates new columns for each category and marks presence with 1 or 0\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df_processed = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
      ],
      "metadata": {
        "id": "vKYH-thoEnMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the processed data\n",
        "print(\"Processed data with one-hot encoding:\")\n",
        "print(df_processed.head())"
      ],
      "metadata": {
        "id": "JYgGRZeHE1eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The target variable is 'salary'. All other columns are features.\n",
        "X = df_processed.drop('salary', axis=1)\n",
        "y = df_processed['salary']"
      ],
      "metadata": {
        "id": "dox68ePxE3MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Data Splitting"
      ],
      "metadata": {
        "id": "KdFGEVpkGpvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Splitting and Model Training\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor # We will use Regressor for demonstration, but Classifier is more appropriate for binary outcome.\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest model.\n",
        "# A Regressor predicts a continuous value. Since our target is 0 or 1, a Classifier would be more standard,\n",
        "# but a Regressor will still work and provides a good learning example.\n",
        "# n_estimators is the number of trees in the forest.\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n"
      ],
      "metadata": {
        "id": "sl_ITqgQE8I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Model Training"
      ],
      "metadata": {
        "id": "M_AnoRc-Gw16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data\n",
        "print(\"Training the Random Forest model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "print(\"\\nPerforming Cross-Validation...\")\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "print(f\"Cross-Validation R2 Scores: {cv_scores}\")\n",
        "print(f\"Average CV R2 Score: {np.mean(cv_scores):.4f}\")"
      ],
      "metadata": {
        "id": "bbHiGRghGuyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Model Evaluation"
      ],
      "metadata": {
        "id": "bplzoO-zG3ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Since the regressor outputs continuous values, we'll round them to get 0 or 1\n",
        "y_pred_classified = np.round(y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred_classified)\n",
        "\n",
        "print(\"\\nModel Performance on Test Set:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (R2 Score): {r2:.4f}\")\n",
        "print(f\"Accuracy Score: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "VSN9Uq_LFBi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classified))"
      ],
      "metadata": {
        "id": "1Yiiuj2_FDGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With the model now trained and evaluated, the next step is to save it for integration into web application(Streamlit)."
      ],
      "metadata": {
        "id": "O1QfLz3sKIoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model and the processed columns to files\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n",
        "joblib.dump(X.columns, 'model_columns.pkl')\n",
        "\n",
        "print(\"\\nModel and columns saved successfully.\")"
      ],
      "metadata": {
        "id": "Q8-HUJmrJFHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GUI of the Web App - Streamlit"
      ],
      "metadata": {
        "id": "U8xjBVXdQT6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file path for **app.py** is: /content/app.py\n",
        "\n",
        "**Steps to launch the web app in Google Colab:**\n",
        "\n",
        "Execute the following commands one at a time.\n",
        "\n",
        "1.Copy the IP address from the Step 2 and then click the link in Step 3 and the press y is asked and then click the link provided.\n",
        "\n",
        "2.Enter the IP address in Tunnel password in the opened website."
      ],
      "metadata": {
        "id": "zTRbV2EzSkR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the Streamlit using PIP.\n",
        "! pip install streamlit -q"
      ],
      "metadata": {
        "id": "je64Cl0sP_GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: This command prints the current public IP address.\n",
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "YnHFkkcDTJQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: This command is used to run a Streamlit app in the background and expose it to the internet using LocalTunnel.\n",
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "-duoMXmbUKI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3ttDwyaV4rP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}